run_id: "MNIST_IGNITE_LIN"

training:
  n_epochs: 1000
  batch_size: 256
  save_period: 50
  image_log_period: 10
  compile_model: true
  use_fourier_sampling: false
  use_amp: false
  manifold_warmup:
    enabled: true
    warmup_epochs: 200
    lambda_tight_start: 0.5 # Starting value of lambda_tight
    schedule_type: "linear" # Type of scheduling ("linear" or "exponential")

losses:
  loss_function: "MSE" # MSE, L1
  tight_clamp: false
  tight_clamp_ratio: 1.5
  lambda_rec: 20
  lambda_idem: 20
  lambda_tight: 2.5         # If warmup is enabled, this value is the end value of lambda_tight

early_stopping:
  patience: 20

optimizer:
  type: "Adam"
  lr: 0.0001
  betas: [0.5, 0.999]

model:
  architecture: "DCGAN_MNIST" # DCGAN & DCGAN_MNIST
  use_bias: false

dataset:
  name: "mnist" # MNIST, CELEBA
  validation_split: 0.1 
  path: "./data"
  download: true
  num_workers: 4
  pin_memory: true
  single_channel: true  # Only used for MNIST

logging:
  log_dir: "runs"

checkpoint:
  save_dir: "checkpoints"

device:
  use_cuda: true
