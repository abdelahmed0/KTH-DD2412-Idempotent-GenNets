run_id: "MNIST_GAUSSIAN_MSE"

training:
  n_epochs: 1000
  batch_size: 512
  save_period: 100
  image_log_period: 10
  compile_model: true
  use_fourier_sampling: false
  manifold_warmup:
    enabled: false
    warmup_epochs: 100
    lambda_tight_start: 0.5 # Starting value of lambda_tight
    schedule_type: "linear" # Type of scheduling ("linear" or "exponential")

losses:
  loss_function: "MSE" # MSE, L1
  lambda_rec: 20
  lambda_idem: 20
  lambda_tight: 2.5         # If warmup is enabled, this value is the end value of lambda_tight
  tight_clamp_ratio: 1.5

optimizer:
  type: "Adam"
  lr: 0.0001
  betas: [0.5, 0.999]

model:
  architecture: "DCGAN_MNIST" # DCGAN & DCGAN_MNIST

dataset:
  name: "mnist" # MNIST, CELEBA
  path: "./data"
  download: true
  num_workers: 5
  pin_memory: true
  single_channel: true  # Only used for MNIST

logging:
  log_dir: "runs"

checkpoint:
  save_dir: "checkpoints"

device:
  use_cuda: true
